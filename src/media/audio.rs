use crate::error::{Result, WatermarkError};
use crate::watermark::dct::DctWatermark;
use crate::watermark::{WatermarkAlgorithm, WatermarkUtils};
use ffmpeg_sidecar::command::FfmpegCommand;
use hound::{SampleFormat, WavReader, WavSpec, WavWriter};
use ndarray::Array2;
use std::path::Path;

/// éŸ³é¢‘æ°´å°å¤„ç†å™¨
pub struct AudioWatermarker;

impl AudioWatermarker {
    /// # åµŒå…¥æ°´å°åˆ°éŸ³é¢‘ä¸­
    ///
    /// # å‚æ•°
    /// * `input_path` - è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    /// * `output_path` - è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    /// * `watermark_text` - æ°´å°æ–‡æœ¬
    /// * `algorithm` - æ°´å°ç®—æ³•
    /// * `strength` - æ°´å°å¼ºåº¦
    ///
    /// # è¿”å›
    /// * `Ok(())` - æˆåŠŸåµŒå…¥æ°´å°
    /// * `Err(WatermarkError)` - åµŒå…¥æ°´å°å¤±è´¥
    pub fn embed_watermark<P: AsRef<Path>>(
        input_path: P,
        output_path: P,
        watermark_text: &str,
        algorithm: &dyn WatermarkAlgorithm,
        strength: f64,
    ) -> Result<()> {
        let input_path = input_path.as_ref();
        let output_path = output_path.as_ref();

        // åˆ›å»ºä¸´æ—¶ç›®å½•
        let temp_dir = std::env::temp_dir().join(format!("audio_watermark_{}", std::process::id()));
        std::fs::create_dir_all(&temp_dir)?;

        // ä½¿ç”¨ffmpegè½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼ˆ16bit 44.1kHz å•å£°é“ WAVï¼‰
        let normalized_audio = temp_dir.join("normalized.wav");
        Self::normalize_audio_format(input_path, &normalized_audio)?;

        // è¯»å–æ ‡å‡†åŒ–åçš„éŸ³é¢‘
        let mut reader = WavReader::open(&normalized_audio)?;
        let spec = reader.spec();

        // è¯»å–éŸ³é¢‘æ ·æœ¬
        let samples: Vec<f64> = reader
            .samples::<i16>()
            .collect::<std::result::Result<Vec<_>, _>>()?
            .into_iter()
            .map(|s| s as f64 / i16::MAX as f64)
            .collect();

        // å°†æ°´å°æ–‡æœ¬è½¬æ¢ä¸ºæ¯”ç‰¹
        let watermark_bits = WatermarkUtils::string_to_bits(watermark_text);

        // ä½¿ç”¨éŸ³é¢‘ä¸“ç”¨DCTç®—æ³•ï¼Œç¡®ä¿æ— å™ªå£°
        let ultra_low_strength = strength * 0.05; // 5%çš„å¼ºåº¦ï¼Œé…åˆéŸ³é¢‘ä¸“ç”¨ç®—æ³•
        println!(
            "ğŸ”‡ ä½¿ç”¨éŸ³é¢‘ä¸“ç”¨DCTæ°´å°ï¼š{ultra_low_strength:.4} (åŸå§‹å¼ºåº¦: {strength:.3})"
        );

        let watermarked_samples =
            Self::ultra_gentle_embed(&samples, &watermark_bits, algorithm, ultra_low_strength)?;

        // åˆ›å»ºä¸´æ—¶æ°´å°éŸ³é¢‘æ–‡ä»¶
        let watermarked_temp = temp_dir.join("watermarked.wav");
        Self::write_wav(&watermarked_temp, &watermarked_samples, spec)?;

        // ä½¿ç”¨ffmpegè½¬æ¢å›åŸå§‹æ ¼å¼
        Self::convert_to_original_format(
            &watermarked_temp,
            &input_path.to_path_buf(),
            &output_path.to_path_buf(),
        )?;

        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        std::fs::remove_dir_all(&temp_dir)?;

        println!("æ°´å°å·²æˆåŠŸåµŒå…¥åˆ°éŸ³é¢‘ä¸­: {output_path:?}");
        println!("ä½¿ç”¨ç®—æ³•: {}", algorithm.name());
        println!("æ°´å°å†…å®¹: {watermark_text}");
        println!("åµŒå…¥å¼ºåº¦: {strength}");

        Ok(())
    }

    /// å°†éŸ³é¢‘æ ‡å‡†åŒ–ä¸ºç»Ÿä¸€æ ¼å¼
    fn normalize_audio_format<P: AsRef<Path>>(input_path: P, output_path: P) -> Result<()> {
        let mut command = FfmpegCommand::new();
        command
            .input(input_path.as_ref().to_str().unwrap())
            .args(["-ac", "1"]) // è½¬æ¢ä¸ºå•å£°é“
            .args(["-ar", "44100"]) // é‡‡æ ·ç‡44.1kHz
            .args(["-acodec", "pcm_s16le"]) // 16ä½PCM
            .args(["-y"]) // è¦†ç›–è¾“å‡ºæ–‡ä»¶
            .output(output_path.as_ref().to_str().unwrap());

        let mut child = command.spawn().map_err(WatermarkError::Io)?;
        let status = child.wait().map_err(WatermarkError::Io)?;

        if !status.success() {
            return Err(WatermarkError::ProcessingError(
                "éŸ³é¢‘æ ¼å¼æ ‡å‡†åŒ–å¤±è´¥".to_string(),
            ));
        }

        Ok(())
    }

    /// å‡†å¤‡æ ·æœ¬ä»¥é€‚åº”æ°´å°ç®—æ³•
    fn prepare_samples_for_watermarking(
        samples: &[f64],
        algorithm: &dyn WatermarkAlgorithm,
    ) -> Result<Vec<f64>> {
        let len = samples.len();
        let matrix_size = (len as f64).sqrt().ceil() as usize;

        let required_size = match algorithm.name() {
            name if name.contains("DCT") => {
                let adjusted_size = matrix_size.div_ceil(8) * 8;
                adjusted_size * adjusted_size
            }
            name if name.contains("DWT") => {
                let adjusted_size = matrix_size.next_power_of_two();
                adjusted_size * adjusted_size
            }
            _ => return Err(WatermarkError::Algorithm("æœªçŸ¥ç®—æ³•".to_string())),
        };

        let mut prepared_samples = samples.to_vec();

        if prepared_samples.len() < required_size {
            // ä½¿ç”¨é›¶å¡«å……è€Œä¸æ˜¯é‡å¤å¡«å……ï¼Œé¿å…å¼•å…¥å™ªå£°
            prepared_samples.resize(required_size, 0.0);
        } else if prepared_samples.len() > required_size {
            prepared_samples.truncate(required_size);
        }

        Ok(prepared_samples)
    }

    /// è½¬æ¢å›åŸå§‹æ ¼å¼
    fn convert_to_original_format<P: AsRef<Path>>(
        watermarked_path: P,
        _original_path: P,
        output_path: P,
    ) -> Result<()> {
        // ç›´æ¥å¤åˆ¶æ°´å°éŸ³é¢‘ï¼Œä¿æŒWAVæ ¼å¼
        let mut command = FfmpegCommand::new();
        command
            .input(watermarked_path.as_ref().to_str().unwrap())
            .args(["-y"])
            .output(output_path.as_ref().to_str().unwrap());

        let mut child = command.spawn().map_err(WatermarkError::Io)?;
        let status = child.wait().map_err(WatermarkError::Io)?;

        if !status.success() {
            return Err(WatermarkError::ProcessingError(
                "éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥".to_string(),
            ));
        }

        Ok(())
    }

    /// # ä»éŸ³é¢‘ä¸­æå–æ°´å°
    ///
    /// # å‚æ•°
    /// * `input_path` - è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    /// * `algorithm` - æ°´å°ç®—æ³•
    /// * `watermark_length` - æœŸæœ›çš„æ°´å°é•¿åº¦
    ///
    /// # è¿”å›
    /// * `Ok(String)` - æå–çš„æ°´å°æ–‡æœ¬
    /// * `Err(WatermarkError)` - æå–æ°´å°å¤±è´¥
    pub fn extract_watermark<P: AsRef<Path>>(
        input_path: P,
        algorithm: &dyn WatermarkAlgorithm,
        watermark_length: usize,
    ) -> Result<String> {
        let input_path = input_path.as_ref();

        // åˆ›å»ºä¸´æ—¶ç›®å½•
        let temp_dir = std::env::temp_dir().join(format!("audio_extract_{}", std::process::id()));
        std::fs::create_dir_all(&temp_dir)?;

        // ä½¿ç”¨ffmpegæ ‡å‡†åŒ–éŸ³é¢‘æ ¼å¼
        let normalized_audio = temp_dir.join("normalized.wav");
        Self::normalize_audio_format(input_path, &normalized_audio)?;

        // è¯»å–æ ‡å‡†åŒ–åçš„éŸ³é¢‘æ–‡ä»¶
        let mut reader = WavReader::open(&normalized_audio)?;
        let _spec = reader.spec();

        // è¯»å–éŸ³é¢‘æ ·æœ¬
        let samples: Vec<f64> = reader
            .samples::<i16>()
            .collect::<std::result::Result<Vec<_>, _>>()?
            .into_iter()
            .map(|s| s as f64 / i16::MAX as f64)
            .collect();

        // ä½¿ç”¨ç›¸åŒçš„éŸ³é¢‘ä¸“ç”¨DCTæå–
        let extracted_bits = Self::ultra_gentle_extract(&samples, algorithm, watermark_length * 8)?;

        // è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        let watermark_text = WatermarkUtils::bits_to_string(&extracted_bits)?;

        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        std::fs::remove_dir_all(&temp_dir)?;

        println!("æ°´å°æå–å®Œæˆ:");
        println!("ä½¿ç”¨ç®—æ³•: {}", algorithm.name());
        println!("æå–åˆ°çš„æ°´å°: {watermark_text}");

        Ok(watermark_text)
    }

    /// å°†éŸ³é¢‘æ ·æœ¬è½¬æ¢ä¸ºäºŒç»´æ•°ç»„
    fn audio_to_array(samples: &[f64]) -> Result<Array2<f64>> {
        let len = samples.len();

        // æ‰¾åˆ°æœ€æ¥è¿‘çš„å®Œå…¨å¹³æ–¹æ•°ä½œä¸ºçŸ©é˜µå°ºå¯¸
        let size = (len as f64).sqrt().ceil() as usize;
        let matrix_size = size.next_power_of_two(); // ç¡®ä¿æ˜¯2çš„å¹‚ï¼Œé€‚ç”¨äºDWT

        let mut array = Array2::<f64>::zeros((matrix_size, matrix_size));

        // å¡«å……æ•°ç»„ï¼Œä¸è¶³çš„éƒ¨åˆ†ç”¨0å¡«å……
        for (i, &sample) in samples.iter().enumerate() {
            if i >= matrix_size * matrix_size {
                break;
            }
            let row = i / matrix_size;
            let col = i % matrix_size;
            array[[row, col]] = sample;
        }

        Ok(array)
    }

    /// å°†äºŒç»´æ•°ç»„è½¬æ¢å›éŸ³é¢‘æ ·æœ¬
    fn array_to_audio(array: &Array2<f64>) -> Result<Vec<f64>> {
        let (rows, cols) = array.dim();
        let mut samples = Vec::new();

        // é¦–å…ˆæ”¶é›†æ‰€æœ‰åŸå§‹æ ·æœ¬
        for i in 0..rows {
            for j in 0..cols {
                samples.push(array[[i, j]]);
            }
        }

        // åº”ç”¨ä¸“ä¸šçš„éŸ³é¢‘å¤„ç†ï¼Œé¿å…ç¡¬é™å¹…å¼•èµ·çš„å¤±çœŸ
        Self::apply_professional_audio_limiting(&mut samples);

        Ok(samples)
    }

    /// ä¸“ä¸šçš„éŸ³é¢‘é™åˆ¶å¤„ç†ï¼Œé¿å…ç¡¬é™å¹…å¤±çœŸ
    fn apply_professional_audio_limiting(samples: &mut [f64]) {
        if samples.is_empty() {
            return;
        }

        // 1. åˆ†æå³°å€¼åˆ†å¸ƒ
        let max_abs = samples.iter().map(|&x| x.abs()).fold(0.0f64, f64::max);

        if max_abs <= 1.0 {
            // å¦‚æœæ²¡æœ‰è¶…é™ï¼Œç›´æ¥è¿”å›
            return;
        }

        println!("æ£€æµ‹åˆ°éŸ³é¢‘å³°å€¼è¶…é™ ({max_abs:.3})ï¼Œåº”ç”¨ä¸“ä¸šéŸ³é¢‘å¤„ç†");

        // 2. ä½¿ç”¨è½¯é™åˆ¶å™¨è€Œä¸æ˜¯ç¡¬é™å¹…
        let threshold = 0.95; // è½¯é™åˆ¶é˜ˆå€¼
        let ratio = 0.2; // å‹ç¼©æ¯”ï¼Œæ›´æ¸©å’Œçš„å¤„ç†

        for sample in samples.iter_mut() {
            *sample = Self::soft_limiter(*sample, threshold, ratio);
        }

        // 3. åº”ç”¨å»åŠ é‡æ»¤æ³¢ï¼Œå‡å°‘é«˜é¢‘å¤±çœŸ
        Self::apply_deemphasis_filter(samples);

        // 4. å¯¹å¼€å¤´åº”ç”¨ç‰¹æ®Šçš„å¹³æ»‘å¤„ç†
        Self::smooth_audio_start(samples);
    }

    /// è½¯é™åˆ¶å™¨ - ä¸“ä¸šéŸ³é¢‘å¤„ç†æŠ€æœ¯
    fn soft_limiter(input: f64, threshold: f64, ratio: f64) -> f64 {
        let abs_input = input.abs();
        let sign = if input >= 0.0 { 1.0 } else { -1.0 };

        if abs_input <= threshold {
            input
        } else {
            // ä½¿ç”¨tanhè½¯é™åˆ¶æ›²çº¿ï¼Œæ¯”ç¡¬é™å¹…å¹³æ»‘å¾—å¤š
            let excess = abs_input - threshold;
            let compressed_excess = excess * ratio;
            let limited_excess = compressed_excess.tanh() * 0.05; // å¾ˆæ¸©å’Œçš„é™åˆ¶
            sign * (threshold + limited_excess)
        }
    }

    /// å»åŠ é‡æ»¤æ³¢å™¨ï¼Œå‡å°‘é«˜é¢‘å¤±çœŸ
    fn apply_deemphasis_filter(samples: &mut [f64]) {
        if samples.len() < 2 {
            return;
        }

        // ç®€å•çš„å»åŠ é‡æ»¤æ³¢å™¨ï¼šy[n] = x[n] + 0.95 * y[n-1]
        let alpha = 0.95;
        let mut prev_output = 0.0;

        for sample in samples.iter_mut() {
            let current_input = *sample;
            let current_output = current_input + alpha * prev_output;
            *sample = current_output;
            prev_output = current_output;
        }

        // åº”ç”¨å½’ä¸€åŒ–ï¼Œé¿å…æ»¤æ³¢å™¨å¼•å…¥çš„å¢ç›Š
        let max_after_filter = samples.iter().map(|&x| x.abs()).fold(0.0f64, f64::max);
        if max_after_filter > 0.98 {
            let normalize_factor = 0.95 / max_after_filter;
            for sample in samples.iter_mut() {
                *sample *= normalize_factor;
            }
        }
    }

    /// å¯¹éŸ³é¢‘å¼€å¤´è¿›è¡Œç‰¹æ®Šå¹³æ»‘å¤„ç†
    fn smooth_audio_start(samples: &mut [f64]) {
        let smooth_length = (samples.len() / 100).clamp(64, 2048); // 1%çš„é•¿åº¦ï¼Œæœ€å°‘64æ ·æœ¬ï¼Œæœ€å¤š2048æ ·æœ¬

        if samples.len() < smooth_length {
            return;
        }

        // å¯¹å¼€å¤´åº”ç”¨Hannçª—å‡½æ•°çš„å‰åŠéƒ¨åˆ†ï¼Œå®ç°å¹³æ»‘å¯åŠ¨
        for (i, sample) in samples.iter_mut().enumerate().take(smooth_length) {
            let window_pos = i as f64 / smooth_length as f64;
            let hann_factor = 0.5 * (1.0 - (2.0 * std::f64::consts::PI * window_pos).cos());
            *sample *= hann_factor;
        }
    }

    /// å†™å…¥WAVæ–‡ä»¶
    fn write_wav<P: AsRef<Path>>(path: P, samples: &[f64], spec: WavSpec) -> Result<()> {
        let mut writer = WavWriter::create(&path, spec)?;

        match spec.sample_format {
            SampleFormat::Float => {
                for &sample in samples.iter() {
                    writer.write_sample(sample as f32)?;
                }
            }
            SampleFormat::Int => {
                // æ ¹æ®å®é™…ä½æ•°è¿›è¡Œè½¬æ¢
                match spec.bits_per_sample {
                    16 => {
                        for &sample in samples.iter() {
                            let int_sample = (sample * i16::MAX as f64) as i16;
                            writer.write_sample(int_sample)?;
                        }
                    }
                    24 => {
                        for &sample in samples.iter() {
                            // 24ä½éŸ³é¢‘å¤„ç†
                            let max_24bit = (1 << 23) - 1; // 2^23 - 1
                            let int_sample = (sample * max_24bit as f64) as i32;
                            writer.write_sample(int_sample)?;
                        }
                    }
                    32 => {
                        for &sample in samples.iter() {
                            let int_sample = (sample * i32::MAX as f64) as i32;
                            writer.write_sample(int_sample)?;
                        }
                    }
                    _ => {
                        return Err(WatermarkError::UnsupportedFormat(format!(
                            "ä¸æ”¯æŒçš„ä½æ·±åº¦: {} bits",
                            spec.bits_per_sample
                        )));
                    }
                }
            }
        }

        writer.finalize()?;
        Ok(())
    }

    /// è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
    pub fn get_audio_info<P: AsRef<Path>>(path: P) -> Result<WavSpec> {
        let reader = WavReader::open(&path)?;
        Ok(reader.spec())
    }

    /// æ£€æŸ¥éŸ³é¢‘æ˜¯å¦é€‚åˆåµŒå…¥æ°´å°
    pub fn check_watermark_capacity<P: AsRef<Path>>(
        path: P,
        watermark_text: &str,
        algorithm: &dyn WatermarkAlgorithm,
    ) -> Result<bool> {
        // è¯»å–éŸ³é¢‘æ–‡ä»¶è·å–æ ·æœ¬æ•°é‡
        let mut reader = WavReader::open(&path)?;
        let spec = reader.spec();
        let watermark_bits = WatermarkUtils::string_to_bits(watermark_text);

        // è®¡ç®—æ€»æ ·æœ¬æ•°
        let total_samples = match spec.sample_format {
            SampleFormat::Float => reader.samples::<f32>().count(),
            SampleFormat::Int => match spec.bits_per_sample {
                16 => reader.samples::<i16>().count(),
                24 | 32 => reader.samples::<i32>().count(),
                _ => {
                    return Err(WatermarkError::UnsupportedFormat(format!(
                        "ä¸æ”¯æŒçš„ä½æ·±åº¦: {} bits",
                        spec.bits_per_sample
                    )));
                }
            },
        };

        let matrix_size = (total_samples as f64).sqrt().ceil() as usize;

        let capacity = match algorithm.name() {
            name if name.contains("DCT") => {
                let adjusted_size = matrix_size.div_ceil(8) * 8;
                (adjusted_size / 8) * (adjusted_size / 8)
            }
            name if name.contains("DWT") => {
                let adjusted_size = if matrix_size % 2 == 0 {
                    matrix_size
                } else {
                    matrix_size + 1
                };
                adjusted_size * adjusted_size / 4
            }
            _ => return Err(WatermarkError::Algorithm("æœªçŸ¥ç®—æ³•".to_string())),
        };

        Ok(watermark_bits.len() <= capacity)
    }

    /// è°ƒæ•´éŸ³é¢‘æ ¼å¼ä»¥é€‚åº”ç®—æ³•è¦æ±‚
    pub fn prepare_audio_for_algorithm<P: AsRef<Path>>(
        input_path: P,
        output_path: P,
        algorithm: &dyn WatermarkAlgorithm,
    ) -> Result<WavSpec> {
        let mut reader = WavReader::open(&input_path)?;
        let mut spec = reader.spec();

        // è½¬æ¢ä¸ºå•å£°é“
        if spec.channels != 1 {
            println!("å°†éŸ³é¢‘è½¬æ¢ä¸ºå•å£°é“...");
            // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥å®ç°ç«‹ä½“å£°åˆ°å•å£°é“çš„è½¬æ¢
            spec.channels = 1;
        }

        // è¯»å–æ ·æœ¬å¹¶é‡æ–°ä¿å­˜
        let samples: Vec<f64> = match spec.sample_format {
            SampleFormat::Float => reader
                .samples::<f32>()
                .collect::<std::result::Result<Vec<_>, _>>()?
                .into_iter()
                .map(|s| s as f64)
                .collect(),
            SampleFormat::Int => {
                // æ ¹æ®ä½æ·±åº¦é€‰æ‹©æ­£ç¡®çš„æ•´æ•°ç±»å‹
                match spec.bits_per_sample {
                    16 => reader
                        .samples::<i16>()
                        .collect::<std::result::Result<Vec<_>, _>>()?
                        .into_iter()
                        .map(|s| s as f64 / i16::MAX as f64)
                        .collect(),
                    24 | 32 => reader
                        .samples::<i32>()
                        .collect::<std::result::Result<Vec<_>, _>>()?
                        .into_iter()
                        .map(|s| {
                            if spec.bits_per_sample == 24 {
                                let max_24bit = (1 << 23) - 1;
                                s as f64 / max_24bit as f64
                            } else {
                                s as f64 / i32::MAX as f64
                            }
                        })
                        .collect(),
                    _ => {
                        return Err(WatermarkError::UnsupportedFormat(format!(
                            "ä¸æ”¯æŒçš„ä½æ·±åº¦: {} bits",
                            spec.bits_per_sample
                        )));
                    }
                }
            }
        };

        // è°ƒæ•´æ ·æœ¬æ•°é‡ä»¥é€‚åº”ç®—æ³•è¦æ±‚
        let len = samples.len();
        let matrix_size = (len as f64).sqrt().ceil() as usize;
        let required_size = match algorithm.name() {
            name if name.contains("DCT") => matrix_size.div_ceil(8) * 8, // 8çš„å€æ•°
            name if name.contains("DWT") => {
                if matrix_size % 2 == 0 {
                    matrix_size
                } else {
                    matrix_size + 1
                }
            } // å¶æ•°
            _ => return Err(WatermarkError::Algorithm("æœªçŸ¥ç®—æ³•".to_string())),
        };

        let required_samples = required_size * required_size;
        let mut adjusted_samples = samples;

        if adjusted_samples.len() < required_samples {
            // ç”¨é›¶å¡«å……
            adjusted_samples.resize(required_samples, 0.0);
        } else if adjusted_samples.len() > required_samples {
            // æˆªæ–­
            adjusted_samples.truncate(required_samples);
        }

        // å†™å…¥è°ƒæ•´åçš„éŸ³é¢‘
        Self::write_wav(&output_path, &adjusted_samples, spec)?;

        println!("éŸ³é¢‘å·²è°ƒæ•´æ ¼å¼ä»¥é€‚åº”{}ç®—æ³•", algorithm.name());

        Ok(spec)
    }

    /// è¶…æ¸©å’ŒéŸ³é¢‘æ°´å°åµŒå…¥ - ä½¿ç”¨ä¸“é—¨çš„éŸ³é¢‘ä¼˜åŒ–DCTç®—æ³•
    fn ultra_gentle_embed(
        samples: &[f64],
        watermark_bits: &[u8],
        algorithm: &dyn WatermarkAlgorithm,
        strength: f64,
    ) -> Result<Vec<f64>> {
        println!("ğŸµ å¼€å§‹éŸ³é¢‘ä¸“ç”¨DCTæ°´å°åµŒå…¥ï¼Œå¼ºåº¦: {strength:.4}");

        // æ£€æŸ¥æ˜¯å¦æ˜¯DCTç®—æ³•ï¼Œå¦‚æœæ˜¯åˆ™ä½¿ç”¨éŸ³é¢‘ä¼˜åŒ–ç‰ˆæœ¬
        if algorithm.name() == "DCT" {
            // ä½¿ç”¨ä¸“é—¨çš„éŸ³é¢‘ä¼˜åŒ–DCTç®—æ³•
            let dct_algorithm = DctWatermark::new();
            let processed_samples = Self::prepare_samples_for_watermarking(samples, algorithm)?;
            let data = Self::audio_to_array(&processed_samples)?;

            // è°ƒç”¨éŸ³é¢‘ä¼˜åŒ–çš„åµŒå…¥æ–¹æ³•
            let watermarked_data =
                dct_algorithm.embed_audio_optimized(&data, watermark_bits, strength)?;
            let mut watermarked_samples = Self::array_to_audio(&watermarked_data)?;

            // æˆªæ–­åˆ°åŸå§‹é•¿åº¦
            if watermarked_samples.len() > samples.len() {
                watermarked_samples.truncate(samples.len());
            }

            // åº”ç”¨è½»é‡åŒ–çš„éŸ³é¢‘åå¤„ç†
            Self::apply_minimal_audio_postprocessing(&mut watermarked_samples);

            println!("âœ… éŸ³é¢‘ä¸“ç”¨DCTæ°´å°åµŒå…¥å®Œæˆ");
            Ok(watermarked_samples)
        } else {
            // å¯¹äºéDCTç®—æ³•ï¼Œä½¿ç”¨åŸæ¥çš„æµç¨‹
            let processed_samples = Self::prepare_samples_for_watermarking(samples, algorithm)?;
            let data = Self::audio_to_array(&processed_samples)?;
            let watermarked_data = algorithm.embed(&data, watermark_bits, strength)?;
            let mut watermarked_samples = Self::array_to_audio(&watermarked_data)?;

            if watermarked_samples.len() > samples.len() {
                watermarked_samples.truncate(samples.len());
            }

            Self::apply_ultra_smooth_audio_pipeline(&mut watermarked_samples, samples);
            println!("âœ… é€šç”¨éŸ³é¢‘æ°´å°åµŒå…¥å®Œæˆ");
            Ok(watermarked_samples)
        }
    }

    /// æ··åˆéŸ³é¢‘æ°´å°æå– - éŸ³é¢‘ä¸“ç”¨åµŒå…¥ä½†æ ‡å‡†æå–
    fn ultra_gentle_extract(
        samples: &[f64],
        algorithm: &dyn WatermarkAlgorithm,
        bit_count: usize,
    ) -> Result<Vec<u8>> {
        println!("ğŸµ å¼€å§‹æ··åˆéŸ³é¢‘æ°´å°æå–ï¼ˆæ ‡å‡†DCTæå–ï¼‰");

        // æ— è®ºä»€ä¹ˆç®—æ³•ï¼Œéƒ½ä½¿ç”¨æ ‡å‡†æå–æµç¨‹
        // å› ä¸ºåµŒå…¥æ—¶è™½ç„¶ç”¨äº†éŸ³é¢‘ä¸“ç”¨ç®—æ³•ï¼Œä½†åŸºæœ¬çš„DCTä½ç½®æ˜¯ç›¸åŒçš„
        let processed_samples = Self::prepare_samples_for_watermarking(samples, algorithm)?;
        let data = Self::audio_to_array(&processed_samples)?;
        let extracted_bits = algorithm.extract(&data, bit_count)?;

        println!("âœ… æ··åˆéŸ³é¢‘æ°´å°æå–å®Œæˆ");
        Ok(extracted_bits)
    }

    /// é«˜çº§éŸ³é¢‘å¹³æ»‘å¤„ç†æµæ°´çº¿ - å½»åº•æ¶ˆé™¤artifactså’Œå™ªå£°
    fn apply_ultra_smooth_audio_pipeline(
        watermarked_samples: &mut [f64],
        original_samples: &[f64],
    ) {
        if watermarked_samples.is_empty() || original_samples.is_empty() {
            return;
        }

        println!("ğŸ”§ åº”ç”¨é«˜çº§éŸ³é¢‘å¹³æ»‘å¤„ç†æµæ°´çº¿...");

        // ç¬¬1æ­¥ï¼šå…¨å±€åŠ¨æ€èŒƒå›´åˆ†æä¸ä¿æŠ¤æ€§å½’ä¸€åŒ–
        let max_abs = watermarked_samples
            .iter()
            .map(|&x| x.abs())
            .fold(0.0f64, f64::max);
        if max_abs > 0.99 {
            let protection_factor = 0.95 / max_abs;
            for sample in watermarked_samples.iter_mut() {
                *sample *= protection_factor;
            }
            println!("  ğŸ“Š åº”ç”¨äº†ä¿æŠ¤æ€§å½’ä¸€åŒ–ï¼Œå› å­: {protection_factor:.4}");
        }

        // ç¬¬2æ­¥ï¼šæ¸©å’Œçš„å…¨å±€ä½é€šæ»¤æ³¢ï¼Œå‡å°‘é«˜é¢‘artifacts
        Self::apply_global_gentle_lowpass(watermarked_samples);

        // ç¬¬3æ­¥ï¼šè‡ªé€‚åº”åŠ¨æ€èŒƒå›´å‹ç¼©
        Self::apply_adaptive_compression(watermarked_samples);

        // ç¬¬4æ­¥ï¼šè¾¹ç•Œå¹³æ»‘å¤„ç†ï¼ˆå¼€å¤´å’Œç»“å°¾ï¼‰
        Self::apply_boundary_smoothing(watermarked_samples);

        // ç¬¬5æ­¥ï¼šæœ€ç»ˆçš„æ„ŸçŸ¥ä¼˜åŒ–é™åˆ¶
        Self::apply_perceptual_limiting(watermarked_samples);

        println!("âœ… é«˜çº§éŸ³é¢‘å¹³æ»‘å¤„ç†å®Œæˆ");
    }

    /// å…¨å±€æ¸©å’Œä½é€šæ»¤æ³¢
    fn apply_global_gentle_lowpass(samples: &mut [f64]) {
        if samples.len() < 3 {
            return;
        }

        // ä½¿ç”¨éå¸¸æ¸©å’Œçš„ä¸‰ç‚¹ç§»åŠ¨å¹³å‡æ»¤æ³¢å™¨
        let alpha = 0.02; // æå°çš„æ»¤æ³¢å¼ºåº¦
        let mut filtered = samples.to_vec();

        for i in 1..samples.len() - 1 {
            let smoothed = (samples[i - 1] + samples[i] * 2.0 + samples[i + 1]) * 0.25;
            filtered[i] = samples[i] * (1.0 - alpha) + smoothed * alpha;
        }

        samples.copy_from_slice(&filtered);
        println!("  ğŸ›ï¸ åº”ç”¨äº†å…¨å±€æ¸©å’Œä½é€šæ»¤æ³¢");
    }

    /// è‡ªé€‚åº”åŠ¨æ€èŒƒå›´å‹ç¼©
    fn apply_adaptive_compression(samples: &mut [f64]) {
        let window_size = 1024;
        let step_size = 512; // 50% overlap

        for start in (0..samples.len()).step_by(step_size) {
            let end = (start + window_size).min(samples.len());
            let window = &mut samples[start..end];

            // è®¡ç®—çª—å£å†…çš„RMS
            let rms = (window.iter().map(|&x| x * x).sum::<f64>() / window.len() as f64).sqrt();

            if rms > 0.1 {
                // åªå¯¹ç›¸å¯¹è¾ƒå¼ºçš„ä¿¡å·åº”ç”¨å‹ç¼©
                let compression_ratio = 0.8 + 0.2 * (0.1 / rms).min(1.0);
                for sample in window.iter_mut() {
                    *sample *= compression_ratio;
                }
            }
        }

        println!("  ğŸšï¸ åº”ç”¨äº†è‡ªé€‚åº”åŠ¨æ€èŒƒå›´å‹ç¼©");
    }

    /// è¾¹ç•Œå¹³æ»‘å¤„ç†
    fn apply_boundary_smoothing(samples: &mut [f64]) {
        let fade_length = (samples.len() / 200).clamp(32, 512); // 0.5%çš„é•¿åº¦ï¼Œ32-512æ ·æœ¬

        // å¼€å¤´æ·¡å…¥
        for i in 0..fade_length.min(samples.len()) {
            let fade_factor = (i as f64 / fade_length as f64).powf(0.5); // å¹³æ–¹æ ¹æ›²çº¿ï¼Œæ›´å¹³æ»‘
            samples[i] *= fade_factor;
        }

        // ç»“å°¾æ·¡å‡º
        let start_fade_out = samples.len().saturating_sub(fade_length);
        for i in start_fade_out..samples.len() {
            let fade_factor = ((samples.len() - i) as f64 / fade_length as f64).powf(0.5);
            samples[i] *= fade_factor;
        }

        println!("  ğŸ­ åº”ç”¨äº†è¾¹ç•Œå¹³æ»‘å¤„ç†ï¼Œæ·¡å…¥æ·¡å‡ºé•¿åº¦: {fade_length}æ ·æœ¬");
    }

    /// æ„ŸçŸ¥ä¼˜åŒ–é™åˆ¶
    fn apply_perceptual_limiting(samples: &mut [f64]) {
        for sample in samples.iter_mut() {
            let abs_val = sample.abs();
            if abs_val > 0.95 {
                let sign = if *sample >= 0.0 { 1.0 } else { -1.0 };
                // ä½¿ç”¨è½¯é™åˆ¶æ›²çº¿
                let excess = abs_val - 0.95;
                let limited_excess = excess.tanh() * 0.04; // éå¸¸æ¸©å’Œçš„é™åˆ¶
                *sample = sign * (0.95 + limited_excess);
            }
        }

        println!("  ğŸ”Š åº”ç”¨äº†æ„ŸçŸ¥ä¼˜åŒ–é™åˆ¶");
    }

    /// è½»é‡åŒ–çš„éŸ³é¢‘åå¤„ç† - ä¸“ä¸ºéŸ³é¢‘ä¼˜åŒ–DCTè®¾è®¡
    fn apply_minimal_audio_postprocessing(samples: &mut [f64]) {
        if samples.is_empty() {
            return;
        }

        println!("ğŸ”§ åº”ç”¨è½»é‡åŒ–éŸ³é¢‘åå¤„ç†...");

        // ç¬¬1æ­¥ï¼šä¿æŠ¤æ€§é™åˆ¶ï¼ˆå¾ˆæ¸©å’Œï¼‰
        let max_abs = samples.iter().map(|&x| x.abs()).fold(0.0f64, f64::max);
        if max_abs > 1.0 {
            let protection_factor = 0.98 / max_abs;
            for sample in samples.iter_mut() {
                *sample *= protection_factor;
            }
            println!("  ğŸ“Š åº”ç”¨äº†ä¿æŠ¤æ€§å½’ä¸€åŒ–ï¼Œå› å­: {protection_factor:.4}");
        }

        // ç¬¬2æ­¥ï¼šæè½»å¾®çš„å¹³æ»‘å¤„ç†
        Self::apply_ultra_light_smoothing(samples);

        // ç¬¬3æ­¥ï¼šè¾¹ç•ŒæŸ”åŒ–ï¼ˆå¾ˆçŸ­çš„æ·¡å…¥æ·¡å‡ºï¼‰
        Self::apply_light_boundary_softening(samples);

        println!("âœ… è½»é‡åŒ–éŸ³é¢‘åå¤„ç†å®Œæˆ");
    }

    /// è¶…è½»å¾®çš„å¹³æ»‘å¤„ç†
    fn apply_ultra_light_smoothing(samples: &mut [f64]) {
        if samples.len() < 3 {
            return;
        }

        // ä½¿ç”¨æè½»å¾®çš„ä¸‰ç‚¹å¹³æ»‘
        let alpha = 0.005; // æå°çš„å¹³æ»‘å¼ºåº¦
        let mut smoothed = samples.to_vec();

        for i in 1..samples.len() - 1 {
            let avg = (samples[i - 1] + samples[i] + samples[i + 1]) / 3.0;
            smoothed[i] = samples[i] * (1.0 - alpha) + avg * alpha;
        }

        samples.copy_from_slice(&smoothed);
        println!("ğŸ›ï¸  åº”ç”¨äº†è¶…è½»å¾®å¹³æ»‘å¤„ç†");
    }

    /// è½»å¾®çš„è¾¹ç•ŒæŸ”åŒ–
    fn apply_light_boundary_softening(samples: &mut [f64]) {
        let fade_length = (samples.len() / 500).clamp(16, 128); // å¾ˆçŸ­çš„æ·¡å…¥æ·¡å‡º

        // å¼€å¤´è½»å¾®æ·¡å…¥
        for i in 0..fade_length.min(samples.len()) {
            let fade_factor = (i as f64 / fade_length as f64).sqrt();
            samples[i] *= fade_factor;
        }

        // ç»“å°¾è½»å¾®æ·¡å‡º
        let start_fade_out = samples.len().saturating_sub(fade_length);
        for i in start_fade_out..samples.len() {
            let fade_factor = ((samples.len() - i) as f64 / fade_length as f64).sqrt();
            samples[i] *= fade_factor;
        }

        println!("ğŸ­ åº”ç”¨äº†è½»å¾®è¾¹ç•ŒæŸ”åŒ–ï¼Œé•¿åº¦: {fade_length}æ ·æœ¬");
    }
}
